---
title: "Predicting exercise correctness using exercise trackers - machine learning course project"
author: "Michael Fierro"
date: "July 2, 2016"
output: html_document
---
# Synopsis
This practice study is based off work done regarding Human Activity Recognition research by Ugulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks, H. Their paper on "Wearable Computing: Accelerometersâ€™ Data
Classification of Body Postures and Movements" relays the benefits of doing exercise correctly, and using activity/exercise trackers to provide feedback on whether an exercixe is being performed correctly. Ugulino, et al. provide the groundwork for such a project, and also provide a dataset containing information from activity trackers from a number of individuals who were performing exercises either correctly or incorrectly. More information can be found in Ugulino, et al.'s paper.

The goal of this project is to create a model which can predict whether an exercise was being performed correctly (optimally). The model will use a variety of predictors to try and predict the classe variable.

```{r}
library(knitr)
library(caret)
library(randomForest)
library(e1071)
```

Import the dataset directly from the proect website into dataframes using read.csv:
```{r}
input_train_data <- read.csv(file="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", na.strings = "NA", stringsAsFactors = FALSE)
input_test_data <- read.csv(file="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", na.strings = "NA", stringsAsFactors = FALSE)
```

The first step in creating a model is to paritition the original input_training_data dataset into training and validation datasets (for cross-validation). The original testing dataset (input_test_data) will not be touched until it is time to use the model

```{r}
set.seed(2048)
inTrain <- createDataPartition(y=input_train_data$classe, p=0.7, list=F)
training <- input_train_data[inTrain, ]
validation <- input_train_data[-inTrain,]
#training size so far:
dim(training)
#validation size so far
dim(validation)
```

Now that we have datasets to work up with, we need to clean up the data: the following code block gets rid of near zero variance variables as well as variables that contain almost nothing but NAs.

```{r clean_up}
# Remove nearZeroVar records
nzw <- nearZeroVar(training)
training <- training[, -nzw]
validation <- validation[, -nzw]

# Remove mostly empty variables:
mostlyEmpty <- sapply(training, function(x) mean(is.na(x))) > 0.9
training <- training[, mostlyEmpty==F]
validation <- validation[, mostlyEmpty==F]
#training size so far:
dim(training)
#validation size so far
dim(validation)
```

There are a lot of variables in the dataframe that simply will not be useful for training. This happens to be the first five variables, which makes it easy to chop up the training and validation dataframes:

```{r trim5}
# The first 5 variables are not candidates for predictors:
names(training[1:5])
training <- training[, -(1:5)]
validation <- validation[, -(1:5)]
```

Now it is time to pick a model. I want to try to reduce error as much as possible *and* I also have some spare processor cycles and time to use, so I'll use a five-fold cross validation - setting this in control:

```{r control}
fitControl <- trainControl(method="cv", number=5, verboseIter=F)
```

At this point, I build my training model using randomForest, fit on the training set:

```{r dotrain}
# fit the model
fitted <- train(classe ~ ., data=training, method="rf", trControl=fitControl)

# show just the result data:
fitted$results
```

Test the model on the validation data:

```{r validate_model}
validationTest <- predict(fitted, newdata=validation)

# Use confusionMatrix to show results:
confusionMatrix(validation$classe, validationTest)

```

The reported accuracy rate of 99.86% is very high, and indicates that the model *should* be reliable for the actual testing data. The last step is to use the model on the actual testing data. This provides the predictions for classe for the 20 entries in the testing dataset:

```{r final_test}
predict(fitted, newdata=input_test_data)
```

Since this is a class project, the automated grading system for Coursera is used to provide answers for the correct classification for classe. The grading system identified my model's predictions above as the correct answers - as expected, this model works well for this assignment.

# Reference
Ugulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks, H. **Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements.** Proceedings of 21st Brazilian Symposium on Artificial Intelligence. Advances in Artificial Intelligence - SBIA 2012. In: Lecture Notes in Computer Science. , pp. 52-61. Curitiba, PR: Springer Berlin / Heidelberg, 2012. ISBN 978-3-642-34458-9. DOI: 10.1007/978-3-642-34459-6_6. 
